{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048eceaa-7a21-4df6-bdd0-4ad46eb2b364",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6dcc23-2cda-4a3b-a699-8f4e1c58df74",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef9090c-ac0b-4294-91c4-e3af6f56a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e7070-f7a0-46d3-bb93-a033fa354012",
   "metadata": {},
   "source": [
    "## Obtaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce5226d-bdd0-4c4c-beff-8288498764e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0                3  \n",
       "1      2401.0      1138.0         8.3014            358500.0                3  \n",
       "2       496.0       177.0         7.2574            352100.0                3  \n",
       "3       558.0       219.0         5.6431            341300.0                3  \n",
       "4       565.0       259.0         3.8462            342200.0                3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../Data/housing_clean.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b728f4-0c94-4f04-9ac7-e03294cc7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'median_house_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440366a5-e883-4d38-b657-be94b4c3c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    if feature == label : continue\n",
    "\n",
    "    data[feature] = (data[feature] - data[feature].min())/(data[feature].max() - data[feature].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24d31bd-3e09-4b7d-9294-22916a557651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.567481</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.539668</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.212151</td>\n",
       "      <td>0.565356</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.180503</td>\n",
       "      <td>0.171477</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.538027</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210159</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.466028</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032352</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.354699</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.043296</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.042427</td>\n",
       "      <td>0.230776</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0   0.211155  0.567481            0.784314     0.022331        0.019863   \n",
       "1   0.212151  0.565356            0.392157     0.180503        0.171477   \n",
       "2   0.210159  0.564293            1.000000     0.037260        0.029330   \n",
       "3   0.209163  0.564293            1.000000     0.032352        0.036313   \n",
       "4   0.209163  0.564293            1.000000     0.041330        0.043296   \n",
       "\n",
       "   population  households  median_income  median_house_value  ocean_proximity  \n",
       "0    0.008941    0.020556       0.539668            452600.0             0.75  \n",
       "1    0.067210    0.186976       0.538027            358500.0             0.75  \n",
       "2    0.013818    0.028943       0.466028            352100.0             0.75  \n",
       "3    0.015555    0.035849       0.354699            341300.0             0.75  \n",
       "4    0.015752    0.042427       0.230776            342200.0             0.75  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace427c3-669d-4011-9d84-810c27dfaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(0.8*len(data))]\n",
    "test_data = data[int(0.8*len(data)):]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "746271b7-75d2-46f9-b46a-901d83199e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = np.asarray(train_data.drop(label,axis=1))\n",
    "train_data_Y = np.asarray(train_data[label])\n",
    "test_data_X = np.asarray(test_data.drop(label,axis=1))\n",
    "test_data_Y = np.asarray(test_data[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a18e10-4965-4915-bb7c-fd6b25742a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16346, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f90b8-3af4-4975-9e9e-5d5627788371",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7717b6-36a4-4b6f-aede-c4fbb41b7a9c",
   "metadata": {},
   "source": [
    "### Decision Tree \n",
    "\n",
    "A decision tree is a binary tree where a decision is made at each node based on a feature and a threshold. The sample points are filtered more and more the further down the tree one goes until ideally, the samples are all of the same class (for classification). Such nodes (called pure nodes) do not need to be divided further and become leaf nodes. For regression, the concept of pure nodes do not exist.\n",
    "\n",
    "To prevent overfitting though, trees are usually not allowed to grow beyond a certain max_depth which usually results in impure leaf nodes. Here, one can take the mode of the samples for classification. For regression, one will always take the mean of any leaf node. \n",
    "\n",
    "The impurity of a node can be measure with Gini impurity for classification and Variance for regression. We want to minimize the gini impurity/variance for each node or in other words **maximize the decrease** in impurity from a parent node to child nodes.\n",
    "\n",
    "$$\\text{Gini impurity, }G = 1 - \\sum_k p_k^2$$\n",
    "\n",
    "$$\\text{where } p_k \\rightarrow \\text{proportion of samples belonging to class k}$$\n",
    "\n",
    "$$\\text{Therefore, we maximize }\\Delta I = I_P - \\left(\\frac{|S_L|}{|S|}I_L - \\frac{|S_R|}{|S|}I_R\\right) \\text  { at each node}$$\n",
    "\n",
    "One tiny flaw with this approach is that it is greedy. It finds the best choice according to the local circumstances only and could potentially lead to sub-optimal trees, but the method is usually good enough for most purposes.\n",
    "\n",
    "One would also stop the growth of a sub-tree if the decrease in impurity isn't significant enough or if the number of samples at a node is smaller than some min_sample number. These measures are also in place to prevent overfitting.\n",
    "\n",
    "Thus the stopping criterions become:\n",
    "1) Depth of the tree is too high, or\n",
    "2) Change in impurity is insignificant or even negative, or\n",
    "3) Number of samples is too little\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "A random forest is an ensemble/collection of decision trees. Instead of relying on a single decision tree for our predictions, the idea is to have many decision trees make their predictions and take their mean or mode. This decreases overfitting that decision trees are somewhat prone to. \n",
    "\n",
    "The problem is that decision trees are deterministic. That means, given a certain training data, the tree will always evolve into the same final tree as long as the parameters are the same. This is where we can harness randomness to our advantage. Instead of letting the decision trees train on the same training data with $N$ samples, we can randomly sample $n$ points (without replacement) and create a random training data for each decision tree in the forest. This process is called \"Bootstrapping\". One can also randomly select a subset of the features as well before sampling the points but this hasn't been done in this notebook. When one obtains bootstrapped data for each tree, it is called \"Bagging\".\n",
    "\n",
    "The rest is self-explanatory. Now we have a collection of trees, and we may take the mode of their predictions for classification or their mean for regression to get the prediction of the forest.\n",
    "\n",
    "### Out of Bag(OOB) Error\n",
    "\n",
    "Out of Bag error is an evaluation metric for random forest. The idea is to let the trees predict on training samples and calculate their error but only the trees that have not utilised the sample in their bootstrapped data will be allowed to predict. This gives a rough idea about how well the model was able to learn the training data without the need of a validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9243c0-f48e-4929-8050-d39fae1c0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_idx=None, threshold=None, left_branch=None, right_branch=None):\n",
    "        self.feature_idx = feature_idx        \n",
    "        self.threshold = threshold     \n",
    "        self.left_branch = left_branch    \n",
    "        self.right_branch = right_branch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f1f25-1e55-4bd3-8625-d793c39c2755",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc1096f-4dcc-426c-b97d-f6d381dd6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isClassification(dtype):\n",
    "    return dtype in ['int32','int64']\n",
    "\n",
    "def getSplit(column, threshold):\n",
    "    left_ids = np.where(column <= threshold)[0]\n",
    "    right_ids = np.where(column > threshold)[0]\n",
    "    return left_ids, right_ids\n",
    "\n",
    "def getImpurity(y):\n",
    "    if isClassification(y.dtype):\n",
    "        classes, counts = np.unique(y)\n",
    "        return 1-np.sum(counts**2)/(len(y)**2)\n",
    "    else:\n",
    "        return np.var(y)\n",
    "\n",
    "def getWeightedImpurity(y, left_ids, right_ids):\n",
    "    total_len = len(left_ids) + len(right_ids)\n",
    "    return (len(left_ids)*getImpurity(y[left_ids]) + len(right_ids)*getImpurity(y[right_ids]))/total_len\n",
    "\n",
    "def getBestSplit(X,y):\n",
    "    best_left_ids = best_right_ids = best_feature_idx = best_threshold = None\n",
    "    best_impurity = float(\"inf\") # Gets the largest float value possible\n",
    "    for feature_idx in range(X.shape[1]):\n",
    "        thresholds = np.unique(X[:,feature_idx])\n",
    "        for threshold in thresholds:\n",
    "            left_ids, right_ids = getSplit(X[:,feature_idx],threshold)\n",
    "            \n",
    "            if len(left_ids)*len(right_ids) == 0:\n",
    "                continue\n",
    "            \n",
    "            weighted_impurity = getWeightedImpurity(y, left_ids, right_ids)\n",
    "\n",
    "            if best_impurity > weighted_impurity:\n",
    "                best_impurity = weighted_impurity\n",
    "                best_left_ids = left_ids\n",
    "                best_right_ids = right_ids\n",
    "                best_feature_idx = feature_idx\n",
    "                best_threshold = threshold\n",
    "                \n",
    "    return best_feature_idx, best_threshold, best_left_ids, best_right_ids\n",
    "\n",
    "def mode(vals):\n",
    "    unique_vals, counts = np.unique(vals,return_counts=True)\n",
    "    return unique_vals[np.argmax(counts)]\n",
    "\n",
    "def getDecisionTree(X, y, depth=0, max_depth=None, min_split=2):\n",
    "    \n",
    "    if ((max_depth is not None and depth >= max_depth) or getImpurity(y) == 0 or len(y) <= min_split):\n",
    "        if isClassification(y.dtype): return mode(y)\n",
    "        else: return np.mean(y)\n",
    "    \n",
    "    feature_idx, threshold, left_ids, right_ids = getBestSplit(X,y)\n",
    "\n",
    "    if feature_idx is None:\n",
    "        if isClassification(y.dtype): return mode(y)\n",
    "        else: return np.mean(y)\n",
    "\n",
    "    left_subtree = getDecisionTree(X[left_ids],y[left_ids], depth + 1, max_depth, min_split)\n",
    "    right_subtree = getDecisionTree(X[right_ids],y[right_ids], depth + 1, max_depth, min_split)\n",
    "    \n",
    "    return Node(feature_idx, threshold, left_subtree, right_subtree)\n",
    "\n",
    "def getPrediction(tree, x):\n",
    "    if not isinstance(tree, Node):\n",
    "        return tree\n",
    "\n",
    "    feature_idx = tree.feature_idx\n",
    "    threshold = tree.threshold\n",
    "    if x[feature_idx] <= threshold:\n",
    "        return getPrediction(tree.left_branch, x)\n",
    "    else:\n",
    "        return getPrediction(tree.right_branch, x)\n",
    "\n",
    "def getPredictionAll(tree,X):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        predictions.append(getPrediction(tree, X[i]))\n",
    "\n",
    "    return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb8c9a-aa85-4160-9b4a-11aafb4db814",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0128a20e-a876-4ce0-a73d-c5ec7cc17c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBootstrappedData(X, y, size=100):\n",
    "    chosen_indices = np.random.randint(0, len(X), size)\n",
    "    unchosen_indices = np.setdiff1d(np.arange(len(X)), np.unique(chosen_indices), assume_unique=True)\n",
    "    return X[chosen_indices], y[chosen_indices], unchosen_indices\n",
    "\n",
    "def fitRandomForest(X, y, size = 100, number_of_trees = 300, max_depth=7, min_samples_split=2, task=\"classification\"):\n",
    "    print(f\"Fitting {number_of_trees} trees for random forest...\") \n",
    "    \n",
    "    trees = []\n",
    "\n",
    "    # 2D list that stores the trees that are not using data-point i into the list at index i\n",
    "    unchosen_indices_list = [[] for _ in range(len(X))]\n",
    "    for tree_idx in range(number_of_trees):\n",
    "        \n",
    "        # Reporting progress\n",
    "        if ((tree_idx+1)%(number_of_trees/10) == 0):\n",
    "            print(100*(tree_idx+1)/(number_of_trees), \"% completed\")\n",
    "\n",
    "        # Get the bootstrapped data\n",
    "        tree_dataX, tree_dataY, unchosen_indices = getBootstrappedData(X, y, size)\n",
    "\n",
    "        # Append the tree_idx into all the lists corresponding to unused data-point index \n",
    "        for idx in unchosen_indices:\n",
    "            unchosen_indices_list[idx].append(tree_idx)\n",
    "            \n",
    "        trees.append(getDecisionTree(tree_dataX,tree_dataY, max_depth=max_depth, min_split = min_samples_split))\n",
    "        \n",
    "    return trees, unchosen_indices_list\n",
    "\n",
    "\n",
    "def predictRandomForest(X,trees,task = \"classification\"):\n",
    "    # Stores the predictions of all the trees\n",
    "    predictions_all = []\n",
    "    for tree in trees:\n",
    "        predictions_all.append(getPredictionAll(tree,X))\n",
    "\n",
    "    predictions_all = np.asarray(predictions_all)\n",
    "\n",
    "    # If categorical, get the mode as the predictions else get the mean\n",
    "    if task == \"classification\":\n",
    "        predictions = []\n",
    "        for i in range(predictions_all.shape[1]):\n",
    "            classes, counts = np.unique(predictions_all[:,i], return_counts = True)\n",
    "            predictions.append(classes[np.argmax(counts)])\n",
    "    else:\n",
    "        predictions = np.mean(predictions_all,axis=0)\n",
    "    return np.asarray(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723e5c2-81fd-43c2-b26c-1cddbe29c1e2",
   "metadata": {},
   "source": [
    "#### Parallelized version of fitRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0611002f-4a9c-47c6-8924-82313d848a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE : This code is only here for faster training times\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def fitRandomForest(X, y, size=100, number_of_trees=300, max_depth=7, min_samples_split=2, task=\"classification\"):\n",
    "    print(f\"Fitting {number_of_trees} trees for random forest...\") \n",
    "\n",
    "    def train_single_tree(_):\n",
    "        tree_dataX, tree_dataY, unchosen_indices = getBootstrappedData(X, y, size)\n",
    "        tree = getDecisionTree(tree_dataX, tree_dataY, max_depth=max_depth, min_split=min_samples_split)\n",
    "        return tree, unchosen_indices\n",
    "\n",
    "    start_time = time.time() \n",
    "    results = Parallel(n_jobs=-1, verbose=0)(\n",
    "        delayed(train_single_tree)(_ if (i % 10 != 0) else print(f\"{100*i/number_of_trees}% completed\")) \n",
    "        for i, _ in enumerate(range(number_of_trees), 1)\n",
    "    )\n",
    "\n",
    "    trees, unchosen_indices_all = zip(*results)\n",
    "\n",
    "    unchosen_indices_list = [[] for _ in range(len(X))]\n",
    "    for tree_idx, unchosen_indices in enumerate(unchosen_indices_all):\n",
    "        for idx in unchosen_indices:\n",
    "            unchosen_indices_list[idx].append(tree_idx)\n",
    "\n",
    "    return list(trees), unchosen_indices_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eaaf85-faf4-463b-9e40-5d3811c5ea35",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469ab115-50fe-4b11-ae0e-9e12f366ee33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 100 trees for random forest...\n",
      "10.0% completed\n",
      "20.0% completed\n",
      "30.0% completed\n",
      "40.0% completed\n",
      "50.0% completed\n",
      "60.0% completed\n",
      "70.0% completed\n",
      "80.0% completed\n",
      "90.0% completed\n",
      "100.0% completed\n"
     ]
    }
   ],
   "source": [
    "trees_reg, unchosen_indices_list_reg = fitRandomForest(train_data_X, train_data_Y, size = 3000,\n",
    "                                                       number_of_trees = 100, min_samples_split = 2,\n",
    "                                                       max_depth = None, task = \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080e225a-3f1f-4d4d-b9e6-1f46596c35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(X, y, trees, task=\"classification\"):\n",
    "    prediction = predictRandomForest(X, trees, task)\n",
    "    if task==\"classification\":\n",
    "        accuracy = np.sum(prediction == y)/len(y)  # Simple accuracy for classification\n",
    "    else:\n",
    "        accuracy = np.mean(np.abs((y-prediction)))  # MAE for regression\n",
    "    return accuracy\n",
    "\n",
    "def getOOBError(X_train, y_train, trees, unchosen_indices_list, task=\"classification\"):\n",
    "    oob_error = 0\n",
    "    for idx in range(len(unchosen_indices_list)):\n",
    "        oob_trees = []\n",
    "        for tree_idx in unchosen_indices_list[idx]:\n",
    "            oob_trees.append(trees[tree_idx])\n",
    "    \n",
    "        prediction = predictRandomForest(X_train[idx:idx+1], oob_trees,task)\n",
    "        if task==\"classification\":\n",
    "            oob_error += np.sum(prediction != y_train[idx:idx+1])  # For classification\n",
    "        else:\n",
    "            oob_error += np.abs((prediction[0] - y_train[idx]))  # For regression\n",
    "    return oob_error/len(unchosen_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79332294-ab35-4fb9-b42c-cb5a05685b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 47518.34171397113\n",
      "OOB Error : 33280.10499832157\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE : {getAccuracy(test_data_X, test_data_Y, trees_reg, task='regression')}\")\n",
    "print(f\"OOB Error : {getOOBError(train_data_X, train_data_Y, trees_reg,unchosen_indices_list_reg,task='regression')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53d289-9930-4c84-b12c-60db8f79775c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
